{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2022-06-08T12:00:59.710861Z","iopub.status.busy":"2022-06-08T12:00:59.710311Z","iopub.status.idle":"2022-06-08T12:00:59.742036Z","shell.execute_reply":"2022-06-08T12:00:59.741174Z","shell.execute_reply.started":"2022-06-08T12:00:59.710751Z"},"trusted":true},"outputs":[],"source":["start = 1000000\n","stop = 2000000"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["!pip install pandas"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2022-06-08T12:01:07.396188Z","iopub.status.busy":"2022-06-08T12:01:07.395268Z","iopub.status.idle":"2022-06-08T12:01:07.624076Z","shell.execute_reply":"2022-06-08T12:01:07.623257Z","shell.execute_reply.started":"2022-06-08T12:01:07.396142Z"},"trusted":true},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import h5py\n","import os"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2022-06-08T11:54:18.228514Z","iopub.status.busy":"2022-06-08T11:54:18.227789Z","iopub.status.idle":"2022-06-08T11:56:00.371171Z","shell.execute_reply":"2022-06-08T11:56:00.369746Z","shell.execute_reply.started":"2022-06-08T11:54:18.228473Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["--2022-06-08 12:27:31--  https://zenodo.org/record/6544649/files/train_sequences.txt?download=1\n","Resolving zenodo.org (zenodo.org)... 137.138.76.77\n","Connecting to zenodo.org (zenodo.org)|137.138.76.77|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 805369640 (768M) [text/plain]\n","Saving to: ‘train_sequences.txt?download=1’\n","\n","train_sequences.txt 100%[===================>] 768.06M  4.57MB/s    in 2m 8s   \n","\n","2022-06-08 12:29:41 (5.99 MB/s) - ‘train_sequences.txt?download=1’ saved [805369640/805369640]\n","\n"]}],"source":["!wget https://zenodo.org/record/6544649/files/train_sequences.txt?download=1\n","!mv train_sequences.txt?download=1 train_sequences.txt"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["--2022-06-09 19:58:13--  https://zenodo.org/record/4436477/files/complex_media_training_data_Glu.txt?download=1\n","Resolving zenodo.org (zenodo.org)... 137.138.76.77\n","Connecting to zenodo.org (zenodo.org)|137.138.76.77|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 3592193655 (3.3G) [text/plain]\n","Saving to: ‘complex_media_training_data_Glu.txt?download=1’\n","\n","complex_media_train 100%[===================>]   3.34G  8.88MB/s    in 3m 39s  \n","\n","2022-06-09 20:01:53 (15.6 MB/s) - ‘complex_media_training_data_Glu.txt?download=1’ saved [3592193655/3592193655]\n","\n"]}],"source":["!wget https://zenodo.org/record/4436477/files/complex_media_training_data_Glu.txt?download=1\n","!mv complex_media_training_data_Glu.txt?download=1 data.text"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2022-06-08T12:01:14.710378Z","iopub.status.busy":"2022-06-08T12:01:14.709911Z","iopub.status.idle":"2022-06-08T12:01:31.258497Z","shell.execute_reply":"2022-06-08T12:01:31.257186Z","shell.execute_reply.started":"2022-06-08T12:01:14.71034Z"},"trusted":true},"outputs":[],"source":["with open('train_sequences.txt') as handle:\n","    raw_data = pd.read_csv(handle, lineterminator='\\n').to_numpy()"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2022-06-08T12:02:10.271211Z","iopub.status.busy":"2022-06-08T12:02:10.270733Z","iopub.status.idle":"2022-06-08T12:02:30.194944Z","shell.execute_reply":"2022-06-08T12:02:30.193709Z","shell.execute_reply.started":"2022-06-08T12:02:10.271172Z"},"trusted":true},"outputs":[{"ename":"","evalue":"","output_type":"error","traceback":["\u001b[1;31mCanceled future for execute_request message before replies were done"]},{"ename":"","evalue":"","output_type":"error","traceback":["\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."]}],"source":["max_length = 0\n","\n","def split_inputs_outputs(a):\n","    global max_length\n","    element = a.split('\\t')\n","    seq, label = element[0], element[1]\n","    pre = 'TGCATTTTTTTCACATC'\n","    post = 'GGTTACGGCTGTT'\n","    seq = seq[len(pre):-len(post)]\n","    max_length = len(seq) if len(seq) > max_length else max_length\n","    return seq, label\n","\n","func = np.vectorize(split_inputs_outputs)\n","temp = np.squeeze(raw_data)\n","inputs, outputs = func(temp)\n","outputs = outputs.astype(np.dtype('f8'))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-06-08T12:03:28.408764Z","iopub.status.busy":"2022-06-08T12:03:28.408175Z","iopub.status.idle":"2022-06-08T12:03:34.752376Z","shell.execute_reply":"2022-06-08T12:03:34.751278Z","shell.execute_reply.started":"2022-06-08T12:03:28.408718Z"},"trusted":true},"outputs":[],"source":["def find_Ns(s):\n","    if 'N' in s:\n","        return 0\n","    else:\n","        return 1\n","\n","func = np.vectorize(find_Ns)\n","mask = func(inputs).astype(bool)\n","spliced_inputs = inputs[mask]\n","spliced_outputs = outputs[mask]\n","print(spliced_inputs.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-06-08T12:03:39.364154Z","iopub.status.busy":"2022-06-08T12:03:39.363747Z","iopub.status.idle":"2022-06-08T12:04:51.943347Z","shell.execute_reply":"2022-06-08T12:04:51.941982Z","shell.execute_reply.started":"2022-06-08T12:03:39.364122Z"},"trusted":true},"outputs":[],"source":["def one_hot_encode(seq, L, i):\n","    if i % 100000 == 0:\n","        print(i//100000)\n","    seq = np.array(list(seq))\n","    encoded = np.zeros((L, 4))\n","    As = np.where(seq == 'A')[0]\n","    Cs = np.where(seq == 'C')[0]\n","    Ts = np.where(seq == 'T')[0]\n","    Gs = np.where(seq == 'G')[0]\n","    encoded[As] = np.array([1, 0, 0, 0])\n","    encoded[Cs] = np.array([0, 1, 0, 0])\n","    encoded[Gs] = np.array([0, 0, 1, 0])\n","    encoded[Ts] = np.array([0, 0, 0, 1])\n","    return encoded\n","\n","order = np.arange(spliced_inputs.shape[0])\n","one_hot_inputs = np.vectorize(one_hot_encode, otypes=[np.ndarray])(spliced_inputs[start:stop], max_length, order[start:stop])\n","one_hot_inputs = np.array(one_hot_inputs.tolist(), dtype=np.dtype('f8'))\n","print(one_hot_inputs.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-06-08T12:06:44.419868Z","iopub.status.busy":"2022-06-08T12:06:44.419277Z","iopub.status.idle":"2022-06-08T12:06:44.425644Z","shell.execute_reply":"2022-06-08T12:06:44.424504Z","shell.execute_reply.started":"2022-06-08T12:06:44.419824Z"},"trusted":true},"outputs":[],"source":["print(spliced_outputs[1])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-06-08T12:06:51.544444Z","iopub.status.busy":"2022-06-08T12:06:51.544021Z","iopub.status.idle":"2022-06-08T12:07:04.673082Z","shell.execute_reply":"2022-06-08T12:07:04.672032Z","shell.execute_reply.started":"2022-06-08T12:06:51.544409Z"},"trusted":true},"outputs":[],"source":["if os.path.exists('dataset.h5'):\n","    os.remove('dataset.h5')\n","    \n","hf = h5py.File('dataset.h5', 'w')\n","print('created file')\n","hf.create_dataset('x_train', data=one_hot_inputs[0:700000], maxshape=(spliced_outputs.shape[0], max_length, 4), chunks=True)\n","print('saved training inputs')\n","hf.create_dataset('y_train', data=spliced_outputs[1000000:1700000], maxshape=(spliced_outputs.shape[0],), chunks=True)\n","print('saved training outputs')\n","hf.create_dataset('x_valid', data=one_hot_inputs[700001:900000], maxshape=(spliced_outputs.shape[0], max_length, 4), chunks=True)\n","print('saved training inputs')\n","hf.create_dataset('y_valid', data=spliced_outputs[1700001:1900000], maxshape=(spliced_outputs.shape[0],), chunks=True)\n","print('saved training outputs')\n","hf.create_dataset('x_test', data=one_hot_inputs[900001:1000000], maxshape=(spliced_outputs.shape[0], max_length, 4), chunks=True)\n","print('saved training inputs')\n","hf.create_dataset('y_test', data=spliced_outputs[1900001:2000000], maxshape=(spliced_outputs.shape[0],), chunks=True)\n","print('saved training outputs')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-06-08T12:08:21.445925Z","iopub.status.busy":"2022-06-08T12:08:21.444979Z","iopub.status.idle":"2022-06-08T12:08:22.50946Z","shell.execute_reply":"2022-06-08T12:08:22.50823Z","shell.execute_reply.started":"2022-06-08T12:08:21.445883Z"},"trusted":true},"outputs":[],"source":["!mv dataset.h5 dataset1.h5"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-06-06T12:55:16.397017Z","iopub.status.busy":"2022-06-06T12:55:16.3964Z","iopub.status.idle":"2022-06-06T12:55:16.405913Z","shell.execute_reply":"2022-06-06T12:55:16.404764Z","shell.execute_reply.started":"2022-06-06T12:55:16.396974Z"},"trusted":true},"outputs":[],"source":["with h5py.File(\"dataset.h5\",\"r\") as f:\n","    print(f.keys())"]},{"cell_type":"markdown","metadata":{},"source":["# 3 mil to 5.5 mil"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from IPython import get_ipython\n","get_ipython().magic('reset -sf')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["start = 3000000\n","stop = 5500000"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import h5py\n","import os"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["with open('train_sequences.txt') as handle:\n","    raw_data = pd.read_csv(handle, sep='\\n').to_numpy()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["max_length = 0\n","\n","def split_inputs_outputs(a):\n","    global max_length\n","    element = a.split('\\t')\n","    seq, label = element[0], element[1]\n","    pre = 'TGCATTTTTTTCACATC'\n","    post = 'GGTTACGGCTGTT'\n","    seq = seq[len(pre):-len(post)]\n","    max_length = len(seq) if len(seq) > max_length else max_length\n","    return seq, label\n","\n","func = np.vectorize(split_inputs_outputs)\n","temp = np.squeeze(raw_data)\n","inputs, outputs = func(temp)\n","outputs = outputs.astype(np.dtype('f8'))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def find_Ns(s):\n","    if 'N' in s:\n","        return 0\n","    else:\n","        return 1\n","\n","func = np.vectorize(find_Ns)\n","mask = func(inputs).astype(bool)\n","spliced_inputs = inputs[mask]\n","spliced_outputs = outputs[mask]\n","print(spliced_inputs.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def one_hot_encode(seq, L, i):\n","    if i % 100000 == 0:\n","        print(i//100000)\n","    seq = np.array(list(seq))\n","    encoded = np.zeros((L, 4))\n","    As = np.where(seq == 'A')[0]\n","    Cs = np.where(seq == 'C')[0]\n","    Ts = np.where(seq == 'T')[0]\n","    Gs = np.where(seq == 'G')[0]\n","    encoded[As] = np.array([1, 0, 0, 0])\n","    encoded[Cs] = np.array([0, 1, 0, 0])\n","    encoded[Gs] = np.array([0, 0, 1, 0])\n","    encoded[Ts] = np.array([0, 0, 0, 1])\n","    return encoded\n","\n","order = np.arange(spliced_inputs.shape[0])\n","one_hot_inputs = np.vectorize(one_hot_encode, otypes=[np.ndarray])(spliced_inputs[start:stop], max_length, order[start:stop])\n","one_hot_inputs = np.array(one_hot_inputs.tolist(), dtype=np.dtype('f8'))\n","print(one_hot_inputs.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["with h5py.File('dataset.h5', 'a') as hf:\n","    hf[\"x_train\"].resize((hf[\"x_train\"].shape[0] + one_hot_inputs.shape[0]), axis = 0)\n","    hf[\"x_train\"][-one_hot_inputs.shape[0]:] = one_hot_inputs\n","    \n","    hf[\"y_train\"].resize((hf[\"y_train\"].shape[0] + one_hot_inputs.shape[0]), axis = 0)\n","    hf[\"y_train\"][-one_hot_inputs.shape[0]:] = spliced_outputs[start:stop]"]},{"cell_type":"markdown","metadata":{},"source":["# 5.5 mil to 6.7 mil"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from IPython import get_ipython\n","get_ipython().magic('reset -sf')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["start = 5500000\n","stop = 6715197"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import h5py\n","import os"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["with open('train_sequences.txt') as handle:\n","    raw_data = pd.read_csv(handle, sep='\\n').to_numpy()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["max_length = 0\n","\n","def split_inputs_outputs(a):\n","    global max_length\n","    element = a.split('\\t')\n","    seq, label = element[0], element[1]\n","    pre = 'TGCATTTTTTTCACATC'\n","    post = 'GGTTACGGCTGTT'\n","    seq = seq[len(pre):-len(post)]\n","    max_length = len(seq) if len(seq) > max_length else max_length\n","    return seq, label\n","\n","func = np.vectorize(split_inputs_outputs)\n","temp = np.squeeze(raw_data)\n","inputs, outputs = func(temp)\n","outputs = outputs.astype(np.dtype('f8'))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def find_Ns(s):\n","    if 'N' in s:\n","        return 0\n","    else:\n","        return 1\n","\n","func = np.vectorize(find_Ns)\n","mask = func(inputs).astype(bool)\n","spliced_inputs = inputs[mask]\n","spliced_outputs = outputs[mask]\n","print(spliced_inputs.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def one_hot_encode(seq, L, i):\n","    if i % 100000 == 0:\n","        print(i//100000)\n","    seq = np.array(list(seq))\n","    encoded = np.zeros((L, 4))\n","    As = np.where(seq == 'A')[0]\n","    Cs = np.where(seq == 'C')[0]\n","    Ts = np.where(seq == 'T')[0]\n","    Gs = np.where(seq == 'G')[0]\n","    encoded[As] = np.array([1, 0, 0, 0])\n","    encoded[Cs] = np.array([0, 1, 0, 0])\n","    encoded[Gs] = np.array([0, 0, 1, 0])\n","    encoded[Ts] = np.array([0, 0, 0, 1])\n","    return encoded\n","\n","order = np.arange(spliced_inputs.shape[0])\n","one_hot_inputs = np.vectorize(one_hot_encode, otypes=[np.ndarray])(spliced_inputs[start:stop], max_length, order[start:stop])\n","one_hot_inputs = np.array(one_hot_inputs.tolist(), dtype=np.dtype('f8'))\n","print(one_hot_inputs.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["with h5py.File('dataset.h5', 'a') as hf:\n","    hf[\"x_train\"].resize((hf[\"x_train\"].shape[0] + one_hot_inputs.shape[0]), axis = 0)\n","    hf[\"x_train\"][-one_hot_inputs.shape[0]:] = one_hot_inputs\n","    \n","    hf[\"y_train\"].resize((hf[\"y_train\"].shape[0] + one_hot_inputs.shape[0]), axis = 0)\n","    hf[\"y_train\"][-one_hot_inputs.shape[0]:] = spliced_outputs[start:stop]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["with h5py.File('dataset.h5', 'a') as hf:\n","    print(hf['x_train'].shape)\n","    print(hf['y_train'].shape)"]}],"metadata":{"interpreter":{"hash":"4f946df053fbf2b937619d3c5458e7af74262f9a954d8797ba0b27400bcafe06"},"kernelspec":{"display_name":"Python 3.10.4 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.4"}},"nbformat":4,"nbformat_minor":4}
